{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "3n3Awkwj7Z8W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_Nlx_23P7Z5K"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oJJXunf7Z26",
        "outputId": "7b437d3f-696c-4f2a-da18-66f84e749bcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BPn0fJ1by9Ve"
      },
      "outputs": [],
      "source": [
        "def count_true(a1, a2):\n",
        "  e = torch.eq(a1, a2)\n",
        "  e = e.cpu().numpy()\n",
        "  c = np.count_nonzero(e)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Pn05zBuxxxMe"
      },
      "outputs": [],
      "source": [
        "def preprocess():\n",
        "   # load the text file\n",
        "    data = open(\"dataset.txt\", 'r').read()\n",
        "    chars = sorted(list(set(data)))\n",
        "    data_size, vocab_size = len(data), len(chars)\n",
        "    \n",
        "    # char to index and index to char maps\n",
        "    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "    ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "    \n",
        "    # convert data from chars to indices\n",
        "    data = list(data)\n",
        "    for i, ch in enumerate(data):\n",
        "        data[i] = char_to_ix[ch]\n",
        "    # data tensor on device\n",
        "    data = torch.tensor(data).to(device)\n",
        "    data = torch.unsqueeze(data, dim=1)\n",
        "    one_hot_encoded = F.one_hot(data).float()\n",
        "    \n",
        "    return data , ix_to_char , data_size, vocab_size, one_hot_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "N250OR8q7Z0Y"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, input_size)\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input_seq, hidden_state):\n",
        "        embedding = self.embedding(input_seq)\n",
        "        output, hidden_state = self.rnn(embedding, hidden_state)\n",
        "        output = self.fc(output)\n",
        "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "aBDr7jEMe1oj"
      },
      "outputs": [],
      "source": [
        "def test(data,data_size,rnn,ix_to_char):\n",
        "\n",
        "        data_ptr = 0\n",
        "        hidden_state = None\n",
        "        # random character\n",
        "        rand_index = np.random.randint(data_size-1)\n",
        "        input_seq = data[rand_index : rand_index+1]\n",
        "        \n",
        "        for i in range(400):\n",
        "          \n",
        "            # forward pass\n",
        "            output, hidden_state = rnn(input_seq, hidden_state)\n",
        "            \n",
        "            # construct categorical distribution and sample a character\n",
        "            output = F.softmax(torch.squeeze(output), dim=0)\n",
        "            dist = Categorical(output)\n",
        "            index = dist.sample()\n",
        "            \n",
        "            # print the sampled character\n",
        "            print(ix_to_char[index.item()], end='')\n",
        "            \n",
        "            # next input is current output\n",
        "            input_seq[0][0] = index.item()\n",
        "            data_ptr += 1\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hvrEkHDd7Ppz"
      },
      "outputs": [],
      "source": [
        "def train(data , ix_to_char, data_size, vocab_size,rnn,epochs,seq_len,loss_fn,optimizer):\n",
        "    acc = []\n",
        "    loss_list = []\n",
        "    for i_epoch in range(1, epochs+1):\n",
        "        \n",
        "        # random starting point (1st 100 chars) from data to begin\n",
        "        data_ptr = np.random.randint(100)\n",
        "        n = 0\n",
        "        running_loss = 0\n",
        "        hidden_state = None\n",
        "        true_predicts = 0\n",
        "        acc = []\n",
        "        loss_list = [] \n",
        "        while True:\n",
        "            input_seq = data[data_ptr : data_ptr+seq_len]\n",
        "            target_seq = data[data_ptr+1 : data_ptr+seq_len+1]\n",
        "            #print(\"target_seq : \",torch.squeeze( target_seq))\n",
        "            \n",
        "            # forward pass\n",
        "            output, hidden_state = rnn(input_seq, hidden_state)\n",
        "            \n",
        "            # compute loss\n",
        "            loss = loss_fn(torch.squeeze(output), torch.squeeze(target_seq))\n",
        "            running_loss += loss.item()\n",
        "            output = F.softmax(torch.squeeze(output), dim=0)\n",
        "            #print(\"output : \", output)\n",
        "            dist = Categorical(output)\n",
        "            #print(\"dist : \", dist)\n",
        "            index = dist.sample()\n",
        "            #print(\"index : \", index)\n",
        "            # compute gradients and take optimizer step\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # compute true predicts\n",
        "            true_predicts += count_true(torch.squeeze( target_seq), index)\n",
        "            \n",
        "            # update the data pointer\n",
        "            data_ptr += seq_len\n",
        "            n +=1\n",
        "            \n",
        "            # if at end of data : break\n",
        "            if data_ptr + seq_len + 1 > data_size:\n",
        "                break\n",
        "        acc.append(true_predicts*100/n)  \n",
        "        loss_list.append(running_loss/n)  \n",
        "        # print loss and save weights after every epoch\n",
        "        print(\"Epoch: {0} \\t Loss: {1:.4f} \\t accuracy: {2:.4f}\".format(i_epoch, running_loss/n,true_predicts*100/data_size))\n",
        "        #torch.save(rnn.state_dict(), save_path)\n",
        "        \n",
        "    return acc,loss_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def runn(hidden_size, seq_len, num_layers, lr, epochs):\n",
        "  # Hyperparameters\n",
        "  hidden_size = hidden_size  \n",
        "  # length of LSTM sequence \n",
        "  seq_len = seq_len\n",
        "  # num of layers in LSTM layer stack      \n",
        "  num_layers =num_layers      \n",
        "  lr = lr   \n",
        "  epochs = epochs\n",
        "  data , ix_to_char, data_size, vocab_size , one_hot_encoded=  preprocess()\n",
        "  # model \n",
        "  rnn = RNN(vocab_size, vocab_size, hidden_size, num_layers).to(device)\n",
        "  # loss function and optimizer\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(rnn.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "  acc_list,loss_list = train(data , ix_to_char, data_size, vocab_size,rnn,epochs,seq_len,loss_fn,optimizer)\n",
        "  print(\"generate text ------------------------------\")\n",
        "  test(data,data_size,rnn,ix_to_char)\n",
        "  return acc_list,loss_list"
      ],
      "metadata": {
        "id": "NPOHloLO3zj7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list,loss_list = runn(512, 250, 3, 0.01, 20)"
      ],
      "metadata": {
        "id": "L5hj0CtKhaRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ddab26-f9ba-484d-8ba6-413b2d236249"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \t Loss: 2.9722 \t accuracy: 1.6665\n",
            "Epoch: 2 \t Loss: 2.2304 \t accuracy: 4.6031\n",
            "Epoch: 3 \t Loss: 1.8061 \t accuracy: 7.9990\n",
            "Epoch: 4 \t Loss: 1.5785 \t accuracy: 10.1823\n",
            "Epoch: 5 \t Loss: 1.4397 \t accuracy: 11.4275\n",
            "Epoch: 6 \t Loss: 1.3485 \t accuracy: 12.2495\n",
            "Epoch: 7 \t Loss: 1.2833 \t accuracy: 12.8821\n",
            "Epoch: 8 \t Loss: 1.2331 \t accuracy: 13.3571\n",
            "Epoch: 9 \t Loss: 1.1920 \t accuracy: 13.6936\n",
            "Epoch: 10 \t Loss: 1.1572 \t accuracy: 14.0096\n",
            "Epoch: 11 \t Loss: 1.1263 \t accuracy: 14.3101\n",
            "Epoch: 12 \t Loss: 1.0982 \t accuracy: 14.5413\n",
            "Epoch: 13 \t Loss: 1.0722 \t accuracy: 14.7159\n",
            "Epoch: 14 \t Loss: 1.0473 \t accuracy: 14.8133\n",
            "Epoch: 15 \t Loss: 1.0233 \t accuracy: 14.9405\n",
            "Epoch: 16 \t Loss: 1.0000 \t accuracy: 15.0789\n",
            "Epoch: 17 \t Loss: 0.9770 \t accuracy: 15.1254\n",
            "Epoch: 18 \t Loss: 0.9540 \t accuracy: 15.1197\n",
            "Epoch: 19 \t Loss: 0.9310 \t accuracy: 15.1636\n",
            "Epoch: 20 \t Loss: 0.9077 \t accuracy: 15.2136\n",
            "generate text ------------------------------\n",
            "ng fouty \"Wais Diggory.\"\n",
            "\"He,\" said Hermione.  Malfoy panced as Harry suddenly.\n",
            "Moody was working fagging even ignoung Harry's wand.\n",
            "\"He escaped the Ministry all good tot take up to the Dark Lord, in her dread might!  you were Cedric, Malfoy . . . excellencus, I was keep tall, and an in touch were mere fifth years ago.  Minerva, and Inven - in a rations, he caught up.\"\n",
            "There was a whisper, he felt"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def runn(hidden_size, seq_len, num_layers, lr, epochs):\n",
        "  # Hyperparameters\n",
        "  hidden_size = hidden_size  \n",
        "  # length of LSTM sequence \n",
        "  seq_len = seq_len\n",
        "  # num of layers in LSTM layer stack      \n",
        "  num_layers =num_layers      \n",
        "  lr = lr   \n",
        "  epochs = epochs\n",
        "  data , ix_to_char, data_size, vocab_size , one_hot_encoded=  preprocess()\n",
        "  # model \n",
        "  rnn = RNN(vocab_size, vocab_size, hidden_size, num_layers).to(device)\n",
        "  # loss function and optimizer\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "  \n",
        "  acc_list,loss_list = train(data , ix_to_char, data_size, vocab_size,rnn,epochs,seq_len,loss_fn,optimizer)\n",
        "  print(\"generate text ------------------------------\")\n",
        "  test(data,data_size,rnn,ix_to_char)\n",
        "  return acc_list,loss_list"
      ],
      "metadata": {
        "id": "XZtoyg4m6WpQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list,loss_list = runn(64, 250, 3, 0.01, 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIk7puqQ3269",
        "outputId": "2c0cbcdc-c124-48c2-f8e2-5b1ef3edec59"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \t Loss: 1.8494 \t accuracy: 13.4557\n",
            "Epoch: 2 \t Loss: 1.6121 \t accuracy: 17.8940\n",
            "Epoch: 3 \t Loss: 1.5882 \t accuracy: 18.9166\n",
            "Epoch: 4 \t Loss: 1.5752 \t accuracy: 19.4338\n",
            "Epoch: 5 \t Loss: 1.5634 \t accuracy: 20.1993\n",
            "Epoch: 6 \t Loss: 1.5538 \t accuracy: 20.9433\n",
            "Epoch: 7 \t Loss: 1.5485 \t accuracy: 21.3221\n",
            "Epoch: 8 \t Loss: 1.5463 \t accuracy: 21.8767\n",
            "Epoch: 9 \t Loss: 1.5507 \t accuracy: 21.9727\n",
            "Epoch: 10 \t Loss: 1.5381 \t accuracy: 22.2864\n",
            "Epoch: 11 \t Loss: 1.5439 \t accuracy: 22.6077\n",
            "Epoch: 12 \t Loss: 1.5341 \t accuracy: 22.9477\n",
            "Epoch: 13 \t Loss: 1.5311 \t accuracy: 23.0985\n",
            "Epoch: 14 \t Loss: 1.5427 \t accuracy: 22.9727\n",
            "Epoch: 15 \t Loss: 1.5523 \t accuracy: 22.7914\n",
            "Epoch: 16 \t Loss: 1.5513 \t accuracy: 23.0826\n",
            "Epoch: 17 \t Loss: 1.5490 \t accuracy: 23.3239\n",
            "Epoch: 18 \t Loss: 1.5563 \t accuracy: 23.5421\n",
            "Epoch: 19 \t Loss: 1.5469 \t accuracy: 23.9405\n",
            "Epoch: 20 \t Loss: 1.5596 \t accuracy: 23.7353\n",
            "Epoch: 21 \t Loss: 1.5556 \t accuracy: 24.0492\n",
            "Epoch: 22 \t Loss: 1.5504 \t accuracy: 24.0721\n",
            "Epoch: 23 \t Loss: 1.5521 \t accuracy: 24.1728\n",
            "Epoch: 24 \t Loss: 1.5619 \t accuracy: 24.3055\n",
            "Epoch: 25 \t Loss: 1.5620 \t accuracy: 24.2178\n",
            "Epoch: 26 \t Loss: 1.5620 \t accuracy: 24.2815\n",
            "Epoch: 27 \t Loss: 1.5659 \t accuracy: 24.4592\n",
            "Epoch: 28 \t Loss: 1.5684 \t accuracy: 24.9416\n",
            "Epoch: 29 \t Loss: 1.5652 \t accuracy: 24.9143\n",
            "Epoch: 30 \t Loss: 1.5734 \t accuracy: 24.7560\n",
            "Epoch: 31 \t Loss: 1.5750 \t accuracy: 25.0595\n",
            "Epoch: 32 \t Loss: 1.5862 \t accuracy: 24.9315\n",
            "Epoch: 33 \t Loss: 1.5814 \t accuracy: 25.1892\n",
            "Epoch: 34 \t Loss: 1.5798 \t accuracy: 25.2660\n",
            "Epoch: 35 \t Loss: 1.5793 \t accuracy: 25.3709\n",
            "Epoch: 36 \t Loss: 1.5769 \t accuracy: 25.4607\n",
            "Epoch: 37 \t Loss: 1.5837 \t accuracy: 25.6475\n",
            "Epoch: 38 \t Loss: 1.5839 \t accuracy: 25.8428\n",
            "Epoch: 39 \t Loss: 1.6016 \t accuracy: 25.5737\n",
            "Epoch: 40 \t Loss: 1.5851 \t accuracy: 26.0469\n",
            "generate text ------------------------------\n",
            "in' leadmen calling anguin at sleuf play's bide not face-ever reside to dirmenting.  They not be trying.  \"She sreattered hit in when not bens, Karimes ho long in clobes.  \"The Geoped, a shape very rone hif sile .meve on grape Lood botacpensiry cart to train wick was will fingers frome on tens to being out recond walking been back had me?\"\n",
            "Winky let you.  Theel red to bred.  H It pair who'r didn't"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o5tXICZp2JVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "mp2_q2_c(1)(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2_miniP1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9a72e0e290b4b52bc83948fc7e01687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9de0f8e7d94744db9a203475a328e728",
              "IPY_MODEL_bb076f9e689b497fbb05ccc59aee8169",
              "IPY_MODEL_80fb13f6003148439779eaf69feac445"
            ],
            "layout": "IPY_MODEL_8d3cf5a0582e4cba9cd06dd374808b72"
          }
        },
        "9de0f8e7d94744db9a203475a328e728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43e83ad14524d0b8439cb99d2d562ca",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7ca754072d412fbe637734088b7590",
            "value": "100%"
          }
        },
        "bb076f9e689b497fbb05ccc59aee8169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1f725479af404fa92eb85c79ecbea3",
            "max": 52147035,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3ab0e2124ee42c28b003397cdf9aad3",
            "value": 52147035
          }
        },
        "80fb13f6003148439779eaf69feac445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_490f02ae601d42d9b56003e15c102d54",
            "placeholder": "​",
            "style": "IPY_MODEL_e26fd4b789524e9681be04c44a467f32",
            "value": " 49.7M/49.7M [00:00&lt;00:00, 145MB/s]"
          }
        },
        "8d3cf5a0582e4cba9cd06dd374808b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f43e83ad14524d0b8439cb99d2d562ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7ca754072d412fbe637734088b7590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1f725479af404fa92eb85c79ecbea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ab0e2124ee42c28b003397cdf9aad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "490f02ae601d42d9b56003e15c102d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26fd4b789524e9681be04c44a467f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**C**"
      ],
      "metadata": {
        "id": "tKIlbaK-sGLh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XaAhfY7RlEY"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d9a72e0e290b4b52bc83948fc7e01687",
            "9de0f8e7d94744db9a203475a328e728",
            "bb076f9e689b497fbb05ccc59aee8169",
            "80fb13f6003148439779eaf69feac445",
            "8d3cf5a0582e4cba9cd06dd374808b72",
            "f43e83ad14524d0b8439cb99d2d562ca",
            "ca7ca754072d412fbe637734088b7590",
            "0f1f725479af404fa92eb85c79ecbea3",
            "c3ab0e2124ee42c28b003397cdf9aad3",
            "490f02ae601d42d9b56003e15c102d54",
            "e26fd4b789524e9681be04c44a467f32"
          ]
        },
        "id": "XnfvbtzmRllT",
        "outputId": "0c5097d5-15f7-4898-dff3-745ab10c15dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/49.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9a72e0e290b4b52bc83948fc7e01687"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "Qobm0gN0bNuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSc7FbUyRlqZ",
        "outputId": "d408ec3d-a32f-45ff-b494-c77efca2f746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3.5607e-02, -2.2878e-01, -3.2326e-01,  5.5471e-02,  1.1363e-01,\n",
            "        -2.8251e-01,  6.1544e-01,  6.0954e-02,  9.4566e-01, -1.4981e+00,\n",
            "        -5.5102e-01, -3.6586e-02, -1.2635e+00, -3.1756e-02,  5.3338e-01,\n",
            "         1.8750e-01,  4.9309e-01, -2.8286e-01, -2.7196e-01, -2.6181e-01,\n",
            "        -3.3155e-01, -7.5719e-02,  6.7103e-02, -5.7090e-01, -5.3175e-01,\n",
            "        -4.9965e-02,  7.2163e-01,  1.1626e+00,  5.1519e-01,  1.3022e+00,\n",
            "         6.9073e-01,  5.5678e-01,  1.3274e-01, -7.1238e-01, -5.0567e-01,\n",
            "        -2.4467e-01, -5.9905e-01,  1.9404e-01, -3.2087e-01,  6.1736e-01,\n",
            "         2.9624e-01, -2.4294e-01,  1.8518e-01, -4.5889e-01,  1.5296e-01,\n",
            "        -6.8361e-01,  9.9018e-01,  6.1654e-01, -1.2935e+00, -4.6649e-01,\n",
            "        -7.1416e-02, -3.3998e-04,  3.7410e-01,  1.8117e-01,  8.5821e-01,\n",
            "         1.0058e+00, -3.0185e-01,  1.9625e-02,  7.9075e-02,  8.1202e-01,\n",
            "         7.7451e-01, -7.0558e-01, -2.2717e-01, -2.5872e-01,  1.5508e-01,\n",
            "        -4.5723e-01,  7.8179e-01,  1.4157e-01,  1.0196e+00, -6.3791e-01,\n",
            "         3.6661e-01, -8.5776e-01,  9.0045e-01,  2.4733e-01,  5.8530e-01,\n",
            "         7.4311e-02,  2.2642e-02, -1.4073e-01,  1.2126e+00,  2.1964e-01,\n",
            "        -4.7912e-01,  2.8475e-02,  5.7822e-01, -7.9263e-01,  2.0452e-01,\n",
            "        -1.3435e+00, -5.2833e-01, -9.1494e-01, -1.0384e+00,  1.2081e+00,\n",
            "         6.7540e-01, -9.7714e-01, -6.2081e-01, -8.3744e-01, -7.9462e-01,\n",
            "        -9.7249e-02, -4.7870e-01, -6.4316e-01, -8.9179e-01,  1.4201e-01,\n",
            "         1.5334e+00, -3.6900e-01,  3.9428e-02, -1.0652e+00,  2.1422e+00,\n",
            "         1.0718e-02,  4.7727e-01, -1.3408e+00, -1.7166e-01, -7.6164e-01,\n",
            "        -8.7233e-03, -1.4409e+00,  7.5086e-01,  1.0382e-01,  9.9494e-01,\n",
            "         7.9119e-01, -5.2683e-01, -1.0767e+00,  1.5027e-01,  1.2637e+00,\n",
            "        -9.0515e-01, -3.5881e-01,  5.3269e-01,  2.3710e-01,  4.7109e-01,\n",
            "         4.2450e-01, -3.2671e-01,  3.7609e-01, -7.7519e-01,  4.1264e-01,\n",
            "        -1.2280e+00, -3.1647e-01,  1.2660e+00, -1.8617e+00, -3.4123e-02,\n",
            "        -2.5280e-01, -1.2166e+00, -1.2271e+00, -1.3598e+00, -6.5225e-01,\n",
            "        -1.0908e+00, -9.2660e-01, -8.1402e-01,  2.3241e-01,  1.2066e-01,\n",
            "        -7.3433e-01,  1.0776e+00, -9.5819e-01, -1.3134e+00, -3.3126e-01,\n",
            "        -1.7443e+00,  8.8546e-01,  2.7585e+00,  2.1534e+00,  2.6076e+00,\n",
            "        -8.4843e-02,  7.0086e-02,  3.2225e+00, -8.2181e-01, -1.1045e+00,\n",
            "        -1.1007e+00, -1.8172e+00, -1.6127e+00, -3.0122e+00, -1.7534e+00,\n",
            "        -1.3869e+00, -1.3422e+00, -2.2503e+00, -1.4988e+00,  8.0288e-01,\n",
            "         2.2173e-01, -1.6786e+00, -1.8998e+00, -4.9848e-01,  1.6308e+00,\n",
            "        -1.1981e+00, -1.6312e+00, -1.1828e+00, -1.5884e+00, -7.8499e-01,\n",
            "        -2.9097e-01, -1.6389e+00, -2.0777e+00, -1.9918e+00, -1.3888e+00,\n",
            "         3.6734e-01,  1.5592e+00, -1.4144e+00, -1.9432e-01, -2.2735e+00,\n",
            "        -1.1240e-01, -2.1212e+00,  1.6591e+00,  5.0070e-01, -8.8058e-01,\n",
            "        -1.0840e+00, -1.9342e+00, -5.3891e-01, -1.4462e+00,  7.3370e-01,\n",
            "         4.4591e-01, -7.7604e-01, -1.5428e+00,  4.7521e+00, -3.7515e-01,\n",
            "        -4.3327e-01, -1.8382e+00,  2.3102e+00,  6.9239e-02, -1.7762e+00,\n",
            "        -2.4657e+00, -1.7878e+00,  2.7571e-01, -1.2037e+00, -7.4176e-01,\n",
            "        -9.9290e-03,  6.5810e-01, -2.2502e-01, -3.4668e-01, -1.4092e+00,\n",
            "        -1.5803e+00, -1.6941e+00,  4.3832e+00,  2.5385e+00,  3.3776e+00,\n",
            "        -1.0301e+00,  9.6489e-01,  8.6440e-02,  9.3403e-01,  2.4959e+00,\n",
            "         3.6288e+00,  3.7899e+00,  3.8152e+00,  2.9073e-01, -2.4349e-01,\n",
            "         8.9794e-01, -2.6600e-01, -1.4105e+00, -6.5378e-01,  8.5767e-01,\n",
            "         6.0564e-01,  6.0313e-01, -1.2349e+00, -1.7813e+00,  1.7007e-01,\n",
            "        -1.5635e+00, -2.5254e+00,  1.0813e+00,  4.7321e+00,  4.2914e+00,\n",
            "         3.9064e+00,  3.9779e-01, -6.3440e-01, -7.8779e-01, -1.0389e+00,\n",
            "        -6.5346e-01,  1.6996e+00,  5.7113e+00,  1.0832e+01,  6.1022e+00,\n",
            "         4.3070e+00,  4.4199e+00, -1.3711e+00,  1.3481e+00,  4.5476e-01,\n",
            "         4.4128e-02, -5.8699e-02,  4.8729e-01, -2.3789e+00,  2.2411e+00,\n",
            "         5.5442e+00, -2.9314e-01, -5.4829e-01,  8.8464e-02,  7.7425e-01,\n",
            "        -2.2289e+00, -1.1821e+00,  5.1806e-01,  1.6654e-02,  5.6978e+00,\n",
            "         3.9968e-01,  6.9130e-01,  5.8708e-01,  3.9757e+00,  1.1034e+00,\n",
            "         2.1488e-01, -9.1533e-01,  1.3669e+00, -4.2841e-01, -2.1551e-01,\n",
            "         2.6103e-02, -6.1778e-01, -6.4612e-02, -6.4966e-01, -2.8096e-01,\n",
            "        -2.0293e-01,  1.2006e+00,  3.4749e-01, -9.2912e-01, -2.7310e-01,\n",
            "         8.4898e-01,  5.0256e-01,  8.5423e-02, -1.8680e-01,  9.1463e-01,\n",
            "        -5.2516e-01,  6.1480e-01, -2.9870e-02, -6.0983e-01, -3.8733e-01,\n",
            "         1.0033e+00,  9.7573e-01,  8.3908e-01,  1.2844e+00,  9.9898e-01,\n",
            "         1.6349e-01,  5.9432e-01,  7.3282e-01,  6.5502e-01,  7.9399e-01,\n",
            "         8.6042e-01,  4.7070e-01, -1.4550e-01,  2.6090e-01,  4.0873e-01,\n",
            "         5.2005e-01,  7.5405e-01,  6.5671e-01, -2.1128e-01,  7.3908e-01,\n",
            "        -1.3712e+00, -1.8747e-01,  2.8425e+00,  1.7757e+00, -1.2110e-01,\n",
            "         5.9487e-01,  2.4049e-01, -4.9349e-01,  9.3597e-01,  1.1249e-01,\n",
            "         1.2116e-01,  9.6989e-02, -1.0692e+00, -1.7705e+00, -1.6674e+00,\n",
            "        -6.4421e-01, -8.1190e-01, -6.0554e-01, -3.2002e-01, -2.1044e+00,\n",
            "        -1.5605e+00, -1.2767e+00, -2.1196e+00, -8.7402e-01, -1.5694e+00,\n",
            "         7.5372e-01,  8.2036e-01, -1.5219e-01,  1.1140e+00,  6.4987e-01,\n",
            "        -1.6276e+00,  1.0295e+00, -6.5943e-01,  1.8632e-01, -1.1066e+00,\n",
            "        -1.4453e+00, -1.1959e+00, -1.4228e+00,  4.1850e-01, -8.1253e-01,\n",
            "        -6.2538e-01, -7.0935e-01, -7.7660e-01,  4.9919e-01,  4.7309e-01,\n",
            "        -1.0971e+00, -1.9222e+00,  9.2840e-01, -1.0064e+00, -1.1537e+00,\n",
            "        -1.0046e-01, -4.6650e-01,  1.4137e-01,  3.6614e-01,  2.3097e-01,\n",
            "        -6.6480e-01, -1.6682e+00,  1.4604e+00,  1.7634e+00, -3.2488e-01,\n",
            "        -3.2992e-01, -2.7372e-01, -1.2326e+00, -1.0563e+00, -5.2048e-01,\n",
            "         3.5363e-01, -1.3362e-01, -1.0854e+00,  5.1892e-01, -6.4103e-01,\n",
            "        -1.0232e+00,  8.0297e-02, -4.9111e-01, -7.3774e-01, -2.1530e-01,\n",
            "        -2.4925e-01, -6.5395e-01, -4.8027e-01, -8.0138e-01,  5.0244e-01,\n",
            "         2.4394e-01, -5.9734e-01,  9.0451e-01, -7.0233e-01,  3.1061e-02,\n",
            "         3.2453e-01, -1.6000e-01, -1.9891e-01, -1.7467e-02,  9.6658e-01,\n",
            "        -3.5370e-01, -1.7970e-01, -1.3314e+00, -3.0983e-01, -1.0982e-01,\n",
            "         1.0997e+00, -1.7973e-01,  2.8900e-01, -1.5428e-01,  4.0363e-01,\n",
            "        -1.1512e+00, -7.3060e-01, -2.6429e-01, -4.5204e-01, -1.0702e+00,\n",
            "         9.9457e-01, -4.5294e-01,  6.5208e-02, -5.2286e-01,  5.2612e-01,\n",
            "         3.0513e-01, -1.6928e-02, -4.3593e-01, -1.1345e-01, -2.6571e-01,\n",
            "         5.4630e-01, -3.1390e-01,  2.6090e-01, -2.4049e-01,  6.2626e-01,\n",
            "        -7.8179e-01, -5.5212e-01, -3.7289e-01,  7.6495e-01,  7.7482e-01,\n",
            "         1.1986e+00, -2.7995e-01, -5.3765e-01,  4.2925e-01, -4.3982e-01,\n",
            "         2.5314e-01, -6.6337e-01,  3.8728e-01,  1.0268e+00, -6.3746e-01,\n",
            "        -2.1882e-01,  6.3782e-02, -6.5960e-01, -5.2809e-01, -9.5180e-01,\n",
            "         3.1120e-01,  5.0105e-01,  6.0200e-01,  6.5831e-01, -5.4279e-01,\n",
            "        -6.6137e-01, -4.5533e-01, -9.3520e-01,  8.8670e-01,  8.5934e-01,\n",
            "        -2.8237e-01, -8.0239e-01, -1.3113e+00,  1.6156e+00,  2.8014e-01,\n",
            "        -1.5627e+00, -3.6159e-01, -7.9473e-01, -3.5516e-01,  1.0328e+00,\n",
            "        -1.1025e+00, -1.0733e+00, -8.6097e-03,  1.0256e-01, -6.0816e-02,\n",
            "         2.2717e-01,  5.7245e-01,  5.3970e-01, -1.0795e+00, -9.2669e-01,\n",
            "        -1.3420e+00, -5.3596e-01,  7.7342e-01, -8.4763e-01, -2.2252e-01,\n",
            "        -5.1444e-01,  6.6312e-02, -8.6819e-02,  2.1138e-01,  8.4519e-01,\n",
            "         3.6555e-01, -6.9170e-01,  2.7504e-02, -5.6335e-01, -3.3489e-01,\n",
            "         1.0908e-01, -5.5583e-01, -6.0106e-01, -1.2104e+00,  5.3710e-01,\n",
            "        -4.8787e-01, -4.1172e-01,  1.2224e+00, -6.9935e-01,  2.4063e-01,\n",
            "         1.0367e-01, -1.4933e-01, -6.7729e-01, -7.9333e-01,  4.5296e-01,\n",
            "        -2.8288e-01,  1.8976e-01, -5.2173e-01, -4.8378e-01,  5.9682e-01,\n",
            "        -5.4344e-01,  1.5581e-01, -4.7818e-02, -5.8863e-01,  2.6965e+00,\n",
            "        -1.3583e+00,  6.0399e-01,  6.7672e-01, -3.3019e-01, -8.1895e-01,\n",
            "        -1.2347e-02, -7.4799e-01, -6.8553e-01, -2.8918e-01,  3.5147e-01,\n",
            "        -3.9225e-01,  3.2456e-01,  6.1160e-02,  1.5760e-01, -1.3476e+00,\n",
            "        -1.0204e+00, -6.3235e-01,  7.5632e-01, -2.5589e-01,  5.0208e-01,\n",
            "        -4.8046e-01, -6.9826e-01, -6.8039e-01, -2.5828e-01, -3.6736e-01,\n",
            "        -7.9490e-01,  9.3736e-01, -2.1486e-01, -2.8257e-01,  7.7238e-01,\n",
            "        -5.3272e-01, -9.5074e-01, -5.3553e-01, -1.0028e+00,  6.0457e-01,\n",
            "        -3.5174e-01, -8.0575e-01,  4.1427e-01,  4.3586e-01, -2.8346e-01,\n",
            "         1.0784e+00, -3.7876e-01,  3.9135e-01, -7.0574e-01, -2.7475e-01,\n",
            "        -2.4859e-01, -3.5297e-01, -1.9707e-01,  4.2274e-01, -9.0614e-01,\n",
            "        -1.0496e+00, -5.5391e-01, -9.9667e-01, -8.6366e-02, -3.7651e-01,\n",
            "         4.5491e-01,  9.6107e-01, -6.7478e-01, -2.6355e-01,  1.2127e-01,\n",
            "        -7.7206e-01, -5.4978e-02, -3.8312e-01, -5.5123e-01,  1.7524e-02,\n",
            "        -9.1819e-01, -3.3785e-01, -3.7212e-01, -5.1973e-01, -7.5171e-01,\n",
            "        -7.0565e-01,  6.6643e-01, -2.2380e-01, -1.2061e+00,  8.8042e-01,\n",
            "        -7.6270e-01, -1.8595e+00, -4.4348e-01, -7.3224e-01, -7.5110e-01,\n",
            "        -1.7356e-01,  1.1147e+00,  8.5556e-01,  2.7333e-01,  6.6173e-01,\n",
            "        -1.4254e-01, -2.8623e-01,  1.5045e-01,  6.6115e-01,  5.8569e-01,\n",
            "         7.6401e-01,  1.3555e+00, -2.2469e-01,  9.4323e-01, -1.1214e+00,\n",
            "         3.0405e-01,  8.5708e-01,  7.0383e-01, -5.5830e-02, -2.8462e-01,\n",
            "         6.4083e-01,  4.3884e-01, -4.5954e-01, -1.9189e-01, -3.8082e-02,\n",
            "        -3.0575e-01,  1.0839e+00, -2.4280e-01,  1.2532e-01,  4.8656e-01,\n",
            "        -1.1438e+00, -8.1460e-01,  1.1255e-02,  8.1423e-01, -6.5076e-01,\n",
            "        -3.1385e-02, -2.2221e-01, -2.3743e-01,  4.9488e-01,  1.5618e-01,\n",
            "         4.1529e-01,  2.1667e-02, -1.5078e+00, -1.2993e-01, -5.1985e-02,\n",
            "         1.5928e-01, -2.0889e-01, -7.4737e-01, -8.7439e-01, -5.9282e-01,\n",
            "         5.9350e-01, -2.7755e-01, -1.9452e-01, -5.6798e-01,  2.7460e-01,\n",
            "        -9.3735e-01,  2.1678e-01,  6.7748e-01, -1.0684e+00, -7.9269e-01,\n",
            "        -4.7843e-01, -1.0534e-01, -8.1416e-01, -9.2718e-01, -8.5372e-02,\n",
            "        -3.0925e-01, -5.9519e-01, -6.9855e-01, -7.4407e-01, -5.8933e-01,\n",
            "        -1.3991e+00, -1.5812e+00,  7.7109e-01, -8.1183e-01, -1.0567e-01,\n",
            "         1.4833e-01,  5.4307e-01, -1.8159e-01,  6.5966e-01, -4.4553e-01,\n",
            "         4.0423e-01, -3.3142e-01, -1.0266e+00,  1.3925e+00, -5.2535e-01,\n",
            "        -8.8450e-01,  8.1033e-01, -8.6215e-01, -5.1140e-02, -8.9545e-01,\n",
            "         1.4049e-01,  8.2730e-01, -8.1306e-02, -3.0760e-01, -1.5938e-02,\n",
            "        -1.4235e+00,  1.4255e+00, -8.3399e-01, -5.6609e-01,  7.8957e-01,\n",
            "         1.1772e-01,  1.1988e-01,  6.4467e-01,  1.3605e+00,  5.7759e-01,\n",
            "        -9.5905e-02, -1.6846e+00,  1.7498e-01,  1.1560e+00, -7.3278e-01,\n",
            "         4.0854e-01,  1.6851e-01, -3.8409e-01,  6.6483e-02, -4.4497e-02,\n",
            "        -3.2634e-01, -7.3040e-01, -3.6167e-02,  3.3436e-01, -1.3387e+00,\n",
            "        -9.0693e-01, -1.1927e-03,  2.9446e-01,  4.3069e-01, -6.8166e-01,\n",
            "        -4.7167e-01, -2.0933e-01, -7.8857e-01,  2.6597e-01,  6.4026e-01,\n",
            "         5.3799e-01, -3.6295e-01, -7.8553e-02,  1.0843e+00, -1.0598e+00,\n",
            "         6.4515e-01,  7.6392e-01, -5.6476e-01,  1.4119e-01,  5.3239e-01,\n",
            "         7.0649e-01,  3.1941e-01, -4.5225e-02,  2.9411e-01, -1.3734e-01,\n",
            "         2.8452e-01,  6.6551e-02, -9.9088e-02,  4.7028e-01, -7.5838e-02,\n",
            "         1.4189e-01, -6.5463e-02,  3.1011e-01, -1.0710e-01,  6.8495e-01,\n",
            "        -4.2108e-01, -3.7335e-01, -1.0715e-01, -2.1595e-01, -2.2912e-01,\n",
            "         1.3451e-01, -4.0129e-01,  1.5042e-01,  7.8969e-01, -5.2447e-01,\n",
            "        -1.4643e+00,  1.2258e-01, -6.1349e-01,  1.2903e+00,  7.4365e-01,\n",
            "        -7.8442e-01, -3.7276e-01,  4.1457e-01, -6.8892e-01, -2.1468e-01,\n",
            "        -1.0444e+00, -1.2021e+00, -4.6715e-01, -8.9998e-01,  8.5642e-01,\n",
            "         7.8103e-02, -1.1772e+00, -1.1222e+00, -1.3061e+00,  4.8075e-01,\n",
            "         1.3086e+00,  6.7640e-01,  1.8485e-01, -1.0501e+00, -1.3882e+00,\n",
            "         2.3545e-01,  9.0298e-01, -1.8194e+00,  2.3997e-01, -8.7795e-03,\n",
            "         1.5278e+00, -3.4627e-01, -4.3690e-01,  2.3463e-01, -1.1197e+00,\n",
            "         1.2962e-01, -5.4479e-01, -2.2730e-01,  2.1024e-01,  3.9196e-02,\n",
            "         7.9660e-01,  5.7951e-01, -5.9427e-01,  4.0452e-01, -2.9030e-01,\n",
            "        -1.5066e+00,  2.0624e-01, -4.5646e-01, -7.4837e-01, -6.1526e-01,\n",
            "        -1.7147e-01, -1.1778e-01, -1.2484e-01,  1.1982e+00, -5.4845e-01,\n",
            "        -1.0519e+00, -4.0591e-01, -3.5259e-01,  5.1157e-01, -3.1235e-01,\n",
            "         3.8747e-01, -1.0345e+00, -1.9627e-01, -8.8467e-01, -3.2809e-01,\n",
            "         2.5163e-01, -7.2509e-01,  1.4092e+00,  9.5120e-01, -3.6204e-01,\n",
            "         2.6323e-01, -9.1472e-01, -7.4253e-01,  1.1217e+00, -6.7554e-01,\n",
            "         6.5347e-01,  6.7347e-01, -8.5280e-01, -4.5023e-01, -7.7801e-01,\n",
            "         7.1291e-02,  5.0682e-01, -4.9282e-01,  2.0158e-01,  1.9136e-01,\n",
            "         1.0317e+00,  7.6617e-03,  5.5710e-02, -9.7061e-01, -4.0203e-01,\n",
            "        -5.0581e-01,  1.1539e+00,  1.5272e-02,  1.6420e-01,  6.4376e-01,\n",
            "        -3.7314e-01, -1.4422e-01,  3.4270e-02, -3.9388e-01, -1.0385e-01,\n",
            "         1.9563e-01,  4.2462e-01, -9.9843e-01,  2.1069e-01, -9.3378e-01,\n",
            "        -1.0217e+00, -5.6076e-01,  5.4740e-01,  6.5389e-02, -5.2482e-01,\n",
            "        -7.7891e-01,  3.0673e-01,  6.1032e-01, -3.8202e-01,  4.9421e-02,\n",
            "        -1.7575e-01, -5.3460e-01,  8.7635e-01, -3.7151e-01,  1.4366e+00,\n",
            "         9.8706e-01, -7.8224e-01, -1.8592e-01, -6.3132e-03, -7.9297e-01,\n",
            "        -3.9622e-01, -1.4567e-01,  1.3112e+00,  1.9927e-01, -7.9441e-01,\n",
            "        -1.0502e+00,  5.2885e-01, -1.0967e+00,  2.0053e-01, -4.3015e-01,\n",
            "         2.6913e-01, -3.8994e-01,  1.8428e-01, -2.8351e-01, -6.0649e-03,\n",
            "         1.1469e-01, -2.9935e-01, -1.9675e-01, -9.3912e-01,  1.5047e+00,\n",
            "         1.3258e-01, -6.5813e-01,  8.4526e-02, -5.6558e-01, -9.1811e-01,\n",
            "        -1.0176e-01,  3.9915e-01,  5.7629e-01,  8.5934e-01,  4.5999e-01,\n",
            "        -8.8732e-01, -9.2226e-01, -4.1232e-01,  8.6883e-01,  2.2862e-01,\n",
            "        -2.0206e-02,  1.1186e+00,  5.0987e-01,  1.0104e+00,  1.2311e+00,\n",
            "        -6.9667e-02,  7.2052e-01, -4.8941e-01,  7.1993e-01, -5.8729e-01,\n",
            "         2.1873e-02,  7.9356e-01,  1.0294e+00,  6.9855e-01, -1.1138e+00,\n",
            "        -1.4502e+00,  6.0494e-01, -5.1734e-01, -2.4062e-01, -4.6572e-01,\n",
            "        -1.1137e+00, -7.3146e-01,  2.8379e-02, -3.7967e-02,  1.7429e-01,\n",
            "         7.7703e-01, -1.4989e-01, -7.5456e-02, -3.8518e-01,  4.7850e-01,\n",
            "         1.3231e+00,  4.8374e-01,  6.9333e-01,  3.0281e-01,  4.4286e-01,\n",
            "         2.3477e-01, -1.7129e-01,  6.4133e-01, -1.1592e-02,  1.2955e+00,\n",
            "         3.3206e-01,  9.0901e-01, -5.5994e-02,  1.9368e-01,  9.3904e-01,\n",
            "         1.7239e+00,  2.4748e-01,  8.6547e-01, -1.0735e+00, -3.2029e-01,\n",
            "         1.0495e-01, -4.5603e-01, -4.7345e-01,  2.9702e-01,  2.9929e-01])\n",
            "tensor([1.9209e-05, 1.4746e-05, 1.3417e-05, 1.9595e-05, 2.0768e-05, 1.3975e-05,\n",
            "        3.4303e-05, 1.9702e-05, 4.7724e-05, 4.1441e-06, 1.0684e-05, 1.7871e-05,\n",
            "        5.2396e-06, 1.7958e-05, 3.1600e-05, 2.2360e-05, 3.0352e-05, 1.3970e-05,\n",
            "        1.4123e-05, 1.4267e-05, 1.3306e-05, 1.7185e-05, 1.9824e-05, 1.0474e-05,\n",
            "        1.0892e-05, 1.7634e-05, 3.8145e-05, 5.9286e-05, 3.1031e-05, 6.8169e-05,\n",
            "        3.6985e-05, 3.2348e-05, 2.1169e-05, 9.0921e-06, 1.1180e-05, 1.4514e-05,\n",
            "        1.0183e-05, 2.2507e-05, 1.3449e-05, 3.4368e-05, 2.4929e-05, 1.4539e-05,\n",
            "        2.2308e-05, 1.1715e-05, 2.1601e-05, 9.3574e-06, 4.9897e-05, 3.4340e-05,\n",
            "        5.0850e-06, 1.1626e-05, 1.7259e-05, 1.8531e-05, 2.6947e-05, 2.2219e-05,\n",
            "        4.3728e-05, 5.0684e-05, 1.3707e-05, 1.8905e-05, 2.0063e-05, 4.1754e-05,\n",
            "        4.0217e-05, 9.1541e-06, 1.4770e-05, 1.4312e-05, 2.1647e-05, 1.1735e-05,\n",
            "        4.0511e-05, 2.1356e-05, 5.1385e-05, 9.7950e-06, 2.6746e-05, 7.8618e-06,\n",
            "        4.5614e-05, 2.3739e-05, 3.3284e-05, 1.9967e-05, 1.8962e-05, 1.6104e-05,\n",
            "        6.2325e-05, 2.3091e-05, 1.1481e-05, 1.9073e-05, 3.3049e-05, 8.3909e-06,\n",
            "        2.2744e-05, 4.8370e-06, 1.0929e-05, 7.4249e-06, 6.5625e-06, 6.2049e-05,\n",
            "        3.6422e-05, 6.9771e-06, 9.9639e-06, 8.0232e-06, 8.3742e-06, 1.6819e-05,\n",
            "        1.1485e-05, 9.7437e-06, 7.5988e-06, 2.1366e-05, 8.5903e-05, 1.2817e-05,\n",
            "        1.9283e-05, 6.3889e-06, 1.5791e-04, 1.8737e-05, 2.9876e-05, 4.8501e-06,\n",
            "        1.5613e-05, 8.6550e-06, 1.8376e-05, 4.3881e-06, 3.9277e-05, 2.0565e-05,\n",
            "        5.0135e-05, 4.0893e-05, 1.0946e-05, 6.3160e-06, 2.1543e-05, 6.5591e-05,\n",
            "        7.4980e-06, 1.2948e-05, 3.1578e-05, 2.3497e-05, 2.9692e-05, 2.8340e-05,\n",
            "        1.3371e-05, 2.7001e-05, 8.5385e-06, 2.8006e-05, 5.4291e-06, 1.3508e-05,\n",
            "        6.5743e-05, 2.8809e-06, 1.7915e-05, 1.4396e-05, 5.4913e-06, 5.4340e-06,\n",
            "        4.7589e-06, 9.6555e-06, 6.2276e-06, 7.3388e-06, 8.2133e-06, 2.3387e-05,\n",
            "        2.0914e-05, 8.8946e-06, 5.4455e-05, 7.1106e-06, 4.9845e-06, 1.3310e-05,\n",
            "        3.2399e-06, 4.4936e-05, 2.9244e-04, 1.5968e-04, 2.5149e-04, 1.7029e-05,\n",
            "        1.9883e-05, 4.6511e-04, 8.1496e-06, 6.1428e-06, 6.1662e-06, 3.0120e-06,\n",
            "        3.6953e-06, 9.1174e-07, 3.2104e-06, 4.6316e-06, 4.8430e-06, 1.9533e-06,\n",
            "        4.1410e-06, 4.1374e-05, 2.3139e-05, 3.4598e-06, 2.7732e-06, 1.1260e-05,\n",
            "        9.4687e-05, 5.5937e-06, 3.6278e-06, 5.6803e-06, 3.7861e-06, 8.4553e-06,\n",
            "        1.3857e-05, 3.5997e-06, 2.3213e-06, 2.5295e-06, 4.6227e-06, 2.6766e-05,\n",
            "        8.8146e-05, 4.5057e-06, 1.5263e-05, 1.9085e-06, 1.6567e-05, 2.2224e-06,\n",
            "        9.7402e-05, 3.0584e-05, 7.6845e-06, 6.2702e-06, 2.6792e-06, 1.0814e-05,\n",
            "        4.3649e-06, 3.8609e-05, 2.8953e-05, 8.5313e-06, 3.9631e-06, 2.1471e-03,\n",
            "        1.2739e-05, 1.2019e-05, 2.9493e-06, 1.8680e-04, 1.9866e-05, 3.1380e-06,\n",
            "        1.5748e-06, 3.1018e-06, 2.4422e-05, 5.5625e-06, 8.8288e-06, 1.8354e-05,\n",
            "        3.5798e-05, 1.4802e-05, 1.3106e-05, 4.5295e-06, 3.8171e-06, 3.4063e-06,\n",
            "        1.4847e-03, 2.3469e-04, 5.4312e-04, 6.6175e-06, 4.8651e-05, 2.0211e-05,\n",
            "        4.7172e-05, 2.2491e-04, 6.9825e-04, 8.2028e-04, 8.4133e-04, 2.4792e-05,\n",
            "        1.4531e-05, 4.5500e-05, 1.4208e-05, 4.5236e-06, 9.6408e-06, 4.3705e-05,\n",
            "        3.3968e-05, 3.3883e-05, 5.3919e-06, 3.1219e-06, 2.1974e-05, 3.8817e-06,\n",
            "        1.4835e-06, 5.4655e-05, 2.1045e-03, 1.3545e-03, 9.2167e-04, 2.7593e-05,\n",
            "        9.8294e-06, 8.4316e-06, 6.5596e-06, 9.6438e-06, 1.0143e-04, 5.6031e-03,\n",
            "        9.3784e-01, 8.2834e-03, 1.3757e-03, 1.5402e-03, 4.7053e-06, 7.1368e-05,\n",
            "        2.9211e-05, 1.9374e-05, 1.7480e-05, 3.0177e-05, 1.7175e-06, 1.7432e-04,\n",
            "        4.7410e-03, 1.3827e-05, 1.0713e-05, 2.0252e-05, 4.0206e-05, 1.9955e-06,\n",
            "        5.6841e-06, 3.1120e-05, 1.8848e-05, 5.5278e-03, 2.7645e-05, 3.7006e-05,\n",
            "        3.3343e-05, 9.8778e-04, 5.5879e-05, 2.2981e-05, 7.4220e-06, 7.2723e-05,\n",
            "        1.2078e-05, 1.4943e-05, 1.9027e-05, 9.9941e-06, 1.7377e-05, 9.6805e-06,\n",
            "        1.3997e-05, 1.5133e-05, 6.1583e-05, 2.6240e-05, 7.3204e-06, 1.4107e-05,\n",
            "        4.3326e-05, 3.0641e-05, 2.0190e-05, 1.5379e-05, 4.6266e-05, 1.0964e-05,\n",
            "        3.4281e-05, 1.7992e-05, 1.0074e-05, 1.2584e-05, 5.0556e-05, 4.9181e-05,\n",
            "        4.2900e-05, 6.6967e-05, 5.0338e-05, 2.1830e-05, 3.3585e-05, 3.8575e-05,\n",
            "        3.5687e-05, 4.1008e-05, 4.3825e-05, 2.9680e-05, 1.6027e-05, 2.4063e-05,\n",
            "        2.7897e-05, 3.1182e-05, 3.9402e-05, 3.5748e-05, 1.5007e-05, 3.8817e-05,\n",
            "        4.7047e-06, 1.5368e-05, 3.1807e-04, 1.0945e-04, 1.6423e-05, 3.3604e-05,\n",
            "        2.3577e-05, 1.1317e-05, 4.7264e-05, 2.0744e-05, 2.0925e-05, 2.0425e-05,\n",
            "        6.3633e-06, 3.1560e-06, 3.4986e-06, 9.7334e-06, 8.2308e-06, 1.0117e-05,\n",
            "        1.3460e-05, 2.2601e-06, 3.8936e-06, 5.1709e-06, 2.2259e-06, 7.7350e-06,\n",
            "        3.8590e-06, 3.9389e-05, 4.2104e-05, 1.5920e-05, 5.6471e-05, 3.5504e-05,\n",
            "        3.6407e-06, 5.1896e-05, 9.5864e-06, 2.2334e-05, 6.1296e-06, 4.3688e-06,\n",
            "        5.6062e-06, 4.4682e-06, 2.8170e-05, 8.2256e-06, 9.9185e-06, 9.1197e-06,\n",
            "        8.5265e-06, 3.0538e-05, 2.9751e-05, 6.1887e-06, 2.7118e-06, 4.6907e-05,\n",
            "        6.7757e-06, 5.8481e-06, 1.6765e-05, 1.1626e-05, 2.1352e-05, 2.6733e-05,\n",
            "        2.3353e-05, 9.5351e-06, 3.4960e-06, 7.9849e-05, 1.0812e-04, 1.3395e-05,\n",
            "        1.3328e-05, 1.4098e-05, 5.4045e-06, 6.4458e-06, 1.1015e-05, 2.6401e-05,\n",
            "        1.6219e-05, 6.2611e-06, 3.1147e-05, 9.7645e-06, 6.6630e-06, 2.0087e-05,\n",
            "        1.1344e-05, 8.8644e-06, 1.4947e-05, 1.4448e-05, 9.6391e-06, 1.1467e-05,\n",
            "        8.3178e-06, 3.0637e-05, 2.3658e-05, 1.0201e-05, 4.5800e-05, 9.1838e-06,\n",
            "        1.9122e-05, 2.5644e-05, 1.5796e-05, 1.5194e-05, 1.8216e-05, 4.8733e-05,\n",
            "        1.3015e-05, 1.5488e-05, 4.8958e-06, 1.3598e-05, 1.6609e-05, 5.5674e-05,\n",
            "        1.5488e-05, 2.4749e-05, 1.5887e-05, 2.7755e-05, 5.8626e-06, 8.9279e-06,\n",
            "        1.4232e-05, 1.1796e-05, 6.3572e-06, 5.0116e-05, 1.1785e-05, 1.9786e-05,\n",
            "        1.0989e-05, 3.1371e-05, 2.5151e-05, 1.8226e-05, 1.1987e-05, 1.6549e-05,\n",
            "        1.4212e-05, 3.2011e-05, 1.3543e-05, 2.4063e-05, 1.4575e-05, 3.4676e-05,\n",
            "        8.4824e-06, 1.0672e-05, 1.2767e-05, 3.9834e-05, 4.0229e-05, 6.1457e-05,\n",
            "        1.4011e-05, 1.0828e-05, 2.8475e-05, 1.1941e-05, 2.3877e-05, 9.5488e-06,\n",
            "        2.7305e-05, 5.1759e-05, 9.7994e-06, 1.4894e-05, 1.9758e-05, 9.5848e-06,\n",
            "        1.0932e-05, 7.1562e-06, 2.5304e-05, 3.0595e-05, 3.3844e-05, 3.5805e-05,\n",
            "        1.0772e-05, 9.5678e-06, 1.1757e-05, 7.2760e-06, 4.4992e-05, 4.3777e-05,\n",
            "        1.3977e-05, 8.3094e-06, 4.9954e-06, 9.3259e-05, 2.4530e-05, 3.8849e-06,\n",
            "        1.2912e-05, 8.3733e-06, 1.2996e-05, 5.2067e-05, 6.1548e-06, 6.3373e-06,\n",
            "        1.8378e-05, 2.0539e-05, 1.7443e-05, 2.3265e-05, 3.2859e-05, 3.1800e-05,\n",
            "        6.2984e-06, 7.3382e-06, 4.8443e-06, 1.0846e-05, 4.0173e-05, 7.9419e-06,\n",
            "        1.4839e-05, 1.1082e-05, 1.9808e-05, 1.6996e-05, 2.2901e-05, 4.3162e-05,\n",
            "        2.6718e-05, 9.2820e-06, 1.9054e-05, 1.0553e-05, 1.3262e-05, 2.0674e-05,\n",
            "        1.0633e-05, 1.0163e-05, 5.5256e-06, 3.1718e-05, 1.1381e-05, 1.2281e-05,\n",
            "        6.2938e-05, 9.2113e-06, 2.3580e-05, 2.0562e-05, 1.5966e-05, 9.4167e-06,\n",
            "        8.3850e-06, 2.9158e-05, 1.3970e-05, 2.2411e-05, 1.1002e-05, 1.1427e-05,\n",
            "        3.3670e-05, 1.0765e-05, 2.1663e-05, 1.7672e-05, 1.0290e-05, 2.7485e-04,\n",
            "        4.7660e-06, 3.3912e-05, 3.6470e-05, 1.3324e-05, 8.1730e-06, 1.8310e-05,\n",
            "        8.7740e-06, 9.3394e-06, 1.3882e-05, 2.6344e-05, 1.2523e-05, 2.5645e-05,\n",
            "        1.9706e-05, 2.1701e-05, 4.8171e-06, 6.6820e-06, 9.8495e-06, 3.9492e-05,\n",
            "        1.4352e-05, 3.0626e-05, 1.1465e-05, 9.2213e-06, 9.3876e-06, 1.4318e-05,\n",
            "        1.2838e-05, 8.3719e-06, 4.7330e-05, 1.4953e-05, 1.3974e-05, 4.0131e-05,\n",
            "        1.0881e-05, 7.1638e-06, 1.0851e-05, 6.8004e-06, 3.3932e-05, 1.3040e-05,\n",
            "        8.2816e-06, 2.8052e-05, 2.8664e-05, 1.3962e-05, 5.4497e-05, 1.2693e-05,\n",
            "        2.7416e-05, 9.1526e-06, 1.4084e-05, 1.4457e-05, 1.3024e-05, 1.5222e-05,\n",
            "        2.8290e-05, 7.4905e-06, 6.4894e-06, 1.0653e-05, 6.8422e-06, 1.7003e-05,\n",
            "        1.2721e-05, 2.9215e-05, 4.8465e-05, 9.4404e-06, 1.4242e-05, 2.0927e-05,\n",
            "        8.5653e-06, 1.7546e-05, 1.2637e-05, 1.0682e-05, 1.8865e-05, 7.4008e-06,\n",
            "        1.3223e-05, 1.2777e-05, 1.1024e-05, 8.7414e-06, 9.1534e-06, 3.6097e-05,\n",
            "        1.4820e-05, 5.5494e-06, 4.4710e-05, 8.6458e-06, 2.8872e-06, 1.1897e-05,\n",
            "        8.9132e-06, 8.7467e-06, 1.5584e-05, 5.6514e-05, 4.3612e-05, 2.4364e-05,\n",
            "        3.5928e-05, 1.6075e-05, 1.3923e-05, 2.1547e-05, 3.5907e-05, 3.3297e-05,\n",
            "        3.9797e-05, 7.1903e-05, 1.4807e-05, 4.7608e-05, 6.0396e-06, 2.5124e-05,\n",
            "        4.3679e-05, 3.7473e-05, 1.7531e-05, 1.3946e-05, 3.5185e-05, 2.8750e-05,\n",
            "        1.1708e-05, 1.5301e-05, 1.7845e-05, 1.3654e-05, 5.4799e-05, 1.4541e-05,\n",
            "        2.1012e-05, 3.0155e-05, 5.9062e-06, 8.2086e-06, 1.8747e-05, 4.1847e-05,\n",
            "        9.6699e-06, 1.7964e-05, 1.4844e-05, 1.4619e-05, 3.0407e-05, 2.1671e-05,\n",
            "        2.8080e-05, 1.8943e-05, 4.1040e-06, 1.6279e-05, 1.7598e-05, 2.1738e-05,\n",
            "        1.5043e-05, 8.7794e-06, 7.7322e-06, 1.0247e-05, 3.3558e-05, 1.4044e-05,\n",
            "        1.5260e-05, 1.0504e-05, 2.4395e-05, 7.2603e-06, 2.3024e-05, 3.6498e-05,\n",
            "        6.3685e-06, 8.3904e-06, 1.1489e-05, 1.6684e-05, 8.2122e-06, 7.3345e-06,\n",
            "        1.7020e-05, 1.3606e-05, 1.0222e-05, 9.2187e-06, 8.8084e-06, 1.0283e-05,\n",
            "        4.5752e-06, 3.8138e-06, 4.0080e-05, 8.2313e-06, 1.6678e-05, 2.1501e-05,\n",
            "        3.1908e-05, 1.5459e-05, 3.5853e-05, 1.1873e-05, 2.7772e-05, 1.3308e-05,\n",
            "        6.6405e-06, 7.4611e-05, 1.0962e-05, 7.6544e-06, 4.1684e-05, 7.8274e-06,\n",
            "        1.7613e-05, 7.5710e-06, 2.1333e-05, 4.2397e-05, 1.7090e-05, 1.3629e-05,\n",
            "        1.8244e-05, 4.4652e-06, 7.7112e-05, 8.0509e-06, 1.0524e-05, 4.0827e-05,\n",
            "        2.0853e-05, 2.0898e-05, 3.5320e-05, 7.2259e-05, 3.3028e-05, 1.6842e-05,\n",
            "        3.4391e-06, 2.2082e-05, 5.8895e-05, 8.9084e-06, 2.7891e-05, 2.1940e-05,\n",
            "        1.2625e-05, 1.9811e-05, 1.7730e-05, 1.3376e-05, 8.9296e-06, 1.7879e-05,\n",
            "        2.5897e-05, 4.8600e-06, 7.4846e-06, 1.8515e-05, 2.4884e-05, 2.8516e-05,\n",
            "        9.3757e-06, 1.1566e-05, 1.5036e-05, 8.4250e-06, 2.4185e-05, 3.5165e-05,\n",
            "        3.1746e-05, 1.2895e-05, 1.7137e-05, 5.4822e-05, 6.4239e-06, 3.5337e-05,\n",
            "        3.9793e-05, 1.0538e-05, 2.1348e-05, 3.1569e-05, 3.7572e-05, 2.5513e-05,\n",
            "        1.7718e-05, 2.4876e-05, 1.6158e-05, 2.4638e-05, 1.9813e-05, 1.6788e-05,\n",
            "        2.9668e-05, 1.7183e-05, 2.1363e-05, 1.7363e-05, 2.5277e-05, 1.6654e-05,\n",
            "        3.6772e-05, 1.2167e-05, 1.2761e-05, 1.6654e-05, 1.4937e-05, 1.4741e-05,\n",
            "        2.1206e-05, 1.2410e-05, 2.1546e-05, 4.0832e-05, 1.0972e-05, 4.2867e-06,\n",
            "        2.0955e-05, 1.0037e-05, 6.7363e-05, 3.8995e-05, 8.4601e-06, 1.2769e-05,\n",
            "        2.8060e-05, 9.3079e-06, 1.4956e-05, 6.5231e-06, 5.5716e-06, 1.1619e-05,\n",
            "        7.5368e-06, 4.3650e-05, 2.0043e-05, 5.7119e-06, 6.0347e-06, 5.0213e-06,\n",
            "        2.9980e-05, 6.8605e-05, 3.6458e-05, 2.2301e-05, 6.4860e-06, 4.6253e-06,\n",
            "        2.3458e-05, 4.5730e-05, 3.0053e-06, 2.3565e-05, 1.8375e-05, 8.5421e-05,\n",
            "        1.3112e-05, 1.1976e-05, 2.3439e-05, 6.0501e-06, 2.1103e-05, 1.0751e-05,\n",
            "        1.4768e-05, 2.2875e-05, 1.9278e-05, 4.1115e-05, 3.3092e-05, 1.0232e-05,\n",
            "        2.7779e-05, 1.3867e-05, 4.1089e-06, 2.2783e-05, 1.1744e-05, 8.7706e-06,\n",
            "        1.0019e-05, 1.5616e-05, 1.6477e-05, 1.6362e-05, 6.1433e-05, 1.0712e-05,\n",
            "        6.4744e-06, 1.2353e-05, 1.3029e-05, 3.0918e-05, 1.3564e-05, 2.7310e-05,\n",
            "        6.5884e-06, 1.5234e-05, 7.6531e-06, 1.3352e-05, 2.3841e-05, 8.9772e-06,\n",
            "        7.5869e-05, 4.7989e-05, 1.2907e-05, 2.4119e-05, 7.4265e-06, 8.8220e-06,\n",
            "        5.6912e-05, 9.4332e-06, 3.5632e-05, 3.6352e-05, 7.9009e-06, 1.1817e-05,\n",
            "        8.5145e-06, 1.9907e-05, 3.0772e-05, 1.1324e-05, 2.2677e-05, 2.2447e-05,\n",
            "        5.2012e-05, 1.8680e-05, 1.9599e-05, 7.0228e-06, 1.2401e-05, 1.1178e-05,\n",
            "        5.8770e-05, 1.8822e-05, 2.1845e-05, 3.5288e-05, 1.2764e-05, 1.6048e-05,\n",
            "        1.9183e-05, 1.2502e-05, 1.6709e-05, 2.2543e-05, 2.8343e-05, 6.8301e-06,\n",
            "        2.2885e-05, 7.2863e-06, 6.6729e-06, 1.0581e-05, 3.2046e-05, 1.9790e-05,\n",
            "        1.0968e-05, 8.5068e-06, 2.5192e-05, 3.4127e-05, 1.2651e-05, 1.9476e-05,\n",
            "        1.5549e-05, 1.0861e-05, 4.4528e-05, 1.2785e-05, 7.7976e-05, 4.9741e-05,\n",
            "        8.4785e-06, 1.5392e-05, 1.8421e-05, 8.3880e-06, 1.2473e-05, 1.6024e-05,\n",
            "        6.8786e-05, 2.2625e-05, 8.3760e-06, 6.4856e-06, 3.1457e-05, 6.1909e-06,\n",
            "        2.2653e-05, 1.2057e-05, 2.4262e-05, 1.2552e-05, 2.2288e-05, 1.3961e-05,\n",
            "        1.8425e-05, 2.0790e-05, 1.3742e-05, 1.5226e-05, 7.2475e-06, 8.3471e-05,\n",
            "        2.1165e-05, 9.5989e-06, 2.0172e-05, 1.0530e-05, 7.4014e-06, 1.6744e-05,\n",
            "        2.7631e-05, 3.2986e-05, 4.3777e-05, 2.9364e-05, 7.6328e-06, 7.3708e-06,\n",
            "        1.2274e-05, 4.4195e-05, 2.3299e-05, 1.8166e-05, 5.6733e-05, 3.0866e-05,\n",
            "        5.0915e-05, 6.3491e-05, 1.7290e-05, 3.8103e-05, 1.1363e-05, 3.8081e-05,\n",
            "        1.0304e-05, 1.8947e-05, 4.0990e-05, 5.1891e-05, 3.7275e-05, 6.0860e-06,\n",
            "        4.3472e-06, 3.3944e-05, 1.1050e-05, 1.4573e-05, 1.1636e-05, 6.0865e-06,\n",
            "        8.9202e-06, 1.9071e-05, 1.7847e-05, 2.2067e-05, 4.0319e-05, 1.5957e-05,\n",
            "        1.7190e-05, 1.2611e-05, 2.9913e-05, 6.9605e-05, 3.0070e-05, 3.7081e-05,\n",
            "        2.5093e-05, 2.8865e-05, 2.3442e-05, 1.5619e-05, 3.5202e-05, 1.8324e-05,\n",
            "        6.7712e-05, 2.5838e-05, 4.6007e-05, 1.7528e-05, 2.2499e-05, 4.7409e-05,\n",
            "        1.0393e-04, 2.3742e-05, 4.4047e-05, 6.3359e-06, 1.3457e-05, 2.0588e-05,\n",
            "        1.1749e-05, 1.1546e-05, 2.4948e-05, 2.5005e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZqCxJYVRlsx",
        "outputId": "08acb1fe-a3e4-4ade-f8fb-7daeadbc9dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-24 12:59:35--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "\rimagenet_classes.tx   0%[                    ]       0  --.-KB/s               \rimagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-24 12:59:35 (62.1 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display(input_image)\n",
        "_, indices = torch.topk(probabilities, 3)\n",
        "for index in indices:\n",
        "    print('Object {} with probability {}'.format(categories[index], probabilities[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0nyXGfdRlvN",
        "outputId": "6e90bf94-1864-4421-9f94-3a4781a27703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object Samoyed with probability 0.9378381967544556\n",
            "Object Pomeranian with probability 0.00828344002366066\n",
            "Object Great Pyrenees with probability 0.005603068508207798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D**"
      ],
      "metadata": {
        "id": "zYWX2_hur_rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from time import time\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.autograph.set_verbosity(0, False)"
      ],
      "metadata": {
        "id": "ppPbQJhzLwmb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwsdmPDyLwvl",
        "outputId": "cb66aa3e-d0cd-4ca6-d2bf-a3a786fd8c86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"y_train:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUsL7gVp84hD",
        "outputId": "10e27ff1-787d-4a4f-d7ba-0b3b0a025489"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train: (50000, 32, 32, 3)\n",
            "y_train: (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "def onehot(a):\n",
        "    a = a.flatten()\n",
        "    o = np.zeros((a.size, a.max() + 1))\n",
        "    o[np.arange(a.size), a] = 1\n",
        "    return o\n",
        "\n",
        "def preprocess(x, y):\n",
        "    y = onehot(y)  # onehot labels\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "fLDKgRbB84kM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, activation_function=\"relu\", \n",
        "                 optimizer=\"adam\", \n",
        "                 loss_function='categorical_crossentropy') -> None:\n",
        "        self.optimizer = optimizer\n",
        "        self.activation_function = activation_function\n",
        "        self.loss_function = loss_function\n",
        "        self.model = self.build_cnn_model()\n",
        "        self.history = None\n",
        "        self.training_time = None\n",
        "        \n",
        "    def build_cnn_model(self):\n",
        "        model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            input_tensor=tf.keras.layers.Resizing(256, 256)(tf.keras.Input(shape=(32, 32, 3)))\n",
        "        )\n",
        "        x = model.layers[-1].output\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "        model = tf.keras.Model(inputs=model.inputs, outputs=x)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=self.optimizer,\n",
        "            loss=self.loss_function,\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "    \n",
        "    def train(self, x_train, y_train, batch_size=32, epochs=50):\n",
        "        self.batch_size = batch_size\n",
        "        assert y_train.shape[1:] == (10, )\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss', \n",
        "            verbose=1,\n",
        "            patience=4,\n",
        "            mode='min',\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "        start = time()\n",
        "        self.history = self.model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping],\n",
        "        )\n",
        "        self.training_time = time() - start\n",
        "    \n",
        "    def plot_history(self):\n",
        "        fig = plt.figure(figsize=(12, 4))\n",
        "        metrics = ['loss', 'accuracy']\n",
        "        for n, metric in enumerate(metrics):\n",
        "            plt.subplot(1, 2, n+1)\n",
        "            plt.plot(self.history.epoch, self.history.history[metric], label='Train')\n",
        "            plt.plot(self.history.epoch, self.history.history[f\"val_{metric}\"], linestyle=\"--\", label='Validation')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel(metric)\n",
        "            plt.title(metric)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        assert y_test.shape[1:] == (10, )\n",
        "        [test_loss,test_acc] = self.model.evaluate(x_test,y_test)\n",
        "        print(\"Test Loss:\", test_loss, \"Test Accuracy:\", test_acc)\n",
        "        test_preds = np.argmax(self.model.predict(x_test), axis=-1)\n",
        "        y_test = np.argmax(y_test, axis=-1)\n",
        "        print(classification_report(y_test, test_preds))\n",
        "      \n",
        "          \n",
        "    def print_summary(self):\n",
        "        print(f\"Training Time: {self.training_time:.2f}s\")\n",
        "        print(\"batch size:\", self.batch_size)\n",
        "        print(\"optimizer:\", self.optimizer)\n",
        "        print(\"activation_function:\", self.activation_function)\n",
        "        print(\"loss_function\", self.loss_function)\n",
        "        print(self.model.summary())\n"
      ],
      "metadata": {
        "id": "5hflepFuOmia"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_processed, y_train_processed = preprocess(x_train, y_train)\n",
        "x_test_processed, y_test_processed = preprocess(x_test, y_test)"
      ],
      "metadata": {
        "id": "9_AByMtSRklR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    activation_function=\"relu\", \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4), \n",
        ")\n",
        "trainer.train(x_train_processed, y_train_processed, \n",
        "              batch_size=128, \n",
        "              epochs=1)\n",
        "trainer.print_summary()\n",
        "trainer.plot_history()\n",
        "trainer.evaluate(x_test_processed, y_test_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SuIbMCzcOmky",
        "outputId": "a3367833-9628-498d-f1c5-0f891a2322cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n",
            "313/313 [==============================] - 428s 1s/step - loss: 0.3623 - accuracy: 0.8803 - val_loss: 0.4926 - val_accuracy: 0.8478\n",
            "Training Time: 451.27s\n",
            "batch size: 128\n",
            "optimizer: <keras.optimizer_v2.adam.Adam object at 0x7fbb6c0ea850>\n",
            "activation_function: relu\n",
            "loss_function categorical_crossentropy\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " resizing (Resizing)            (None, 256, 256, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 127, 127, 32  864         ['resizing[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 127, 127, 32  96         ['conv2d_94[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 127, 127, 32  0           ['batch_normalization_94[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 125, 125, 32  9216        ['activation_94[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 125, 125, 32  96         ['conv2d_95[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 125, 125, 32  0           ['batch_normalization_95[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 125, 125, 64  18432       ['activation_95[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 125, 125, 64  192        ['conv2d_96[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 125, 125, 64  0           ['batch_normalization_96[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 62, 62, 64)  0           ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 62, 62, 80)   5120        ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 62, 62, 80)  240         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 62, 62, 80)   0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 60, 60, 192)  138240      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 60, 60, 192)  576        ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 60, 60, 192)  0           ['batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 29, 29, 192)  0          ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 29, 29, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 29, 29, 64)  192         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 29, 29, 48)   9216        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 29, 29, 48)  144         ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 29, 29, 96)  288         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_9 (AveragePo  (None, 29, 29, 192)  0          ['max_pooling2d_5[0][0]']        \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 29, 29, 64)   12288       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 29, 29, 32)   6144        ['average_pooling2d_9[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 29, 29, 64)  192         ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 29, 29, 64)  192         ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 29, 29, 96)  288         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 29, 29, 32)  96          ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 29, 29, 64)   0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 29, 29, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 29, 29, 256)  0           ['activation_99[0][0]',          \n",
            "                                                                  'activation_101[0][0]',         \n",
            "                                                                  'activation_104[0][0]',         \n",
            "                                                                  'activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 29, 29, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 29, 29, 64)  192         ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 29, 29, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 29, 29, 48)  144         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 29, 29, 96)  288         ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_10 (AverageP  (None, 29, 29, 256)  0          ['mixed0[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 29, 29, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 29, 29, 64)   16384       ['average_pooling2d_10[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 29, 29, 64)  192         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 29, 29, 64)  192         ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 29, 29, 96)  288         ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 29, 29, 64)  192         ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 29, 29, 288)  0           ['activation_106[0][0]',         \n",
            "                                                                  'activation_108[0][0]',         \n",
            "                                                                  'activation_111[0][0]',         \n",
            "                                                                  'activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 29, 29, 64)  192         ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 29, 29, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 29, 29, 48)  144         ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 29, 29, 96)  288         ['conv2d_117[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 29, 29, 48)   0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_11 (AverageP  (None, 29, 29, 288)  0          ['mixed1[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 29, 29, 64)   76800       ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_118 (Conv2D)            (None, 29, 29, 96)   82944       ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_119 (Conv2D)            (None, 29, 29, 64)   18432       ['average_pooling2d_11[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 29, 29, 64)  192         ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 29, 29, 64)  192         ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 29, 29, 96)  288         ['conv2d_118[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 29, 29, 64)  192         ['conv2d_119[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 29, 29, 288)  0           ['activation_113[0][0]',         \n",
            "                                                                  'activation_115[0][0]',         \n",
            "                                                                  'activation_118[0][0]',         \n",
            "                                                                  'activation_119[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_121 (Conv2D)            (None, 29, 29, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 29, 29, 64)  192         ['conv2d_121[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 29, 29, 64)   0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_122 (Conv2D)            (None, 29, 29, 96)   55296       ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 29, 29, 96)  288         ['conv2d_122[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 29, 29, 96)   0           ['batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_120 (Conv2D)            (None, 14, 14, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_123 (Conv2D)            (None, 14, 14, 96)   82944       ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 14, 14, 384)  1152       ['conv2d_120[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 14, 14, 96)  288         ['conv2d_123[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 14, 14, 384)  0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 14, 14, 96)   0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 14, 14, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 14, 14, 768)  0           ['activation_120[0][0]',         \n",
            "                                                                  'activation_123[0][0]',         \n",
            "                                                                  'max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_128 (Conv2D)            (None, 14, 14, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 14, 14, 128)  384        ['conv2d_128[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_129 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 14, 14, 128)  384        ['conv2d_129[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_125 (Conv2D)            (None, 14, 14, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_130 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 14, 14, 128)  384        ['conv2d_125[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 14, 14, 128)  384        ['conv2d_130[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_126 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_131 (Conv2D)            (None, 14, 14, 128)  114688      ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 14, 14, 128)  384        ['conv2d_126[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 14, 14, 128)  384        ['conv2d_131[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 14, 14, 128)  0           ['batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_12 (AverageP  (None, 14, 14, 768)  0          ['mixed3[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_124 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_127 (Conv2D)            (None, 14, 14, 192)  172032      ['activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_132 (Conv2D)            (None, 14, 14, 192)  172032      ['activation_131[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_133 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_12[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 14, 14, 192)  576        ['conv2d_124[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 14, 14, 192)  576        ['conv2d_127[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 14, 14, 192)  576        ['conv2d_132[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 14, 14, 192)  576        ['conv2d_133[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 14, 14, 768)  0           ['activation_124[0][0]',         \n",
            "                                                                  'activation_127[0][0]',         \n",
            "                                                                  'activation_132[0][0]',         \n",
            "                                                                  'activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_138 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 14, 14, 160)  480        ['conv2d_138[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_139 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 14, 14, 160)  480        ['conv2d_139[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_135 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 14, 14, 160)  480        ['conv2d_135[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 14, 14, 160)  480        ['conv2d_140[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_136 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 14, 14, 160)  480        ['conv2d_136[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 14, 14, 160)  480        ['conv2d_141[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_13 (AverageP  (None, 14, 14, 768)  0          ['mixed4[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_134 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_137 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_143 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_13[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 14, 14, 192)  576        ['conv2d_134[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 14, 14, 192)  576        ['conv2d_137[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 14, 14, 192)  576        ['conv2d_142[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 14, 14, 192)  576        ['conv2d_143[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 14, 14, 768)  0           ['activation_134[0][0]',         \n",
            "                                                                  'activation_137[0][0]',         \n",
            "                                                                  'activation_142[0][0]',         \n",
            "                                                                  'activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_148 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 14, 14, 160)  480        ['conv2d_148[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 14, 14, 160)  480        ['conv2d_149[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)            (None, 14, 14, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 14, 14, 160)  480        ['conv2d_145[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 14, 14, 160)  480        ['conv2d_150[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)            (None, 14, 14, 160)  179200      ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 14, 14, 160)  480        ['conv2d_146[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 14, 14, 160)  480        ['conv2d_151[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 14, 14, 160)  0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_14 (AverageP  (None, 14, 14, 768)  0          ['mixed5[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)            (None, 14, 14, 192)  215040      ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_14[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 14, 14, 192)  576        ['conv2d_144[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 14, 14, 192)  576        ['conv2d_147[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 14, 14, 192)  576        ['conv2d_152[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 14, 14, 192)  576        ['conv2d_153[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 14, 14, 768)  0           ['activation_144[0][0]',         \n",
            "                                                                  'activation_147[0][0]',         \n",
            "                                                                  'activation_152[0][0]',         \n",
            "                                                                  'activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 14, 14, 192)  576        ['conv2d_158[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 14, 14, 192)  576        ['conv2d_159[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 14, 14, 192)  576        ['conv2d_155[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 14, 14, 192)  576        ['conv2d_160[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 14, 14, 192)  576        ['conv2d_156[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 14, 14, 192)  576        ['conv2d_161[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " average_pooling2d_15 (AverageP  (None, 14, 14, 768)  0          ['mixed6[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 14, 14, 192)  147456      ['average_pooling2d_15[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 14, 14, 192)  576        ['conv2d_154[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 14, 14, 192)  576        ['conv2d_157[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 14, 14, 192)  576        ['conv2d_162[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 14, 14, 192)  576        ['conv2d_163[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 14, 14, 768)  0           ['activation_154[0][0]',         \n",
            "                                                                  'activation_157[0][0]',         \n",
            "                                                                  'activation_162[0][0]',         \n",
            "                                                                  'activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 14, 14, 192)  576        ['conv2d_166[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 14, 14, 192)  576        ['conv2d_167[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 14, 14, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 14, 14, 192)  258048      ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 14, 14, 192)  576        ['conv2d_164[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 14, 14, 192)  576        ['conv2d_168[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 14, 14, 192)  0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 6, 6, 320)    552960      ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 6, 6, 192)    331776      ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 6, 6, 320)   960         ['conv2d_165[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 6, 6, 192)   576         ['conv2d_169[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 6, 6, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 6, 6, 1280)   0           ['activation_165[0][0]',         \n",
            "                                                                  'activation_169[0][0]',         \n",
            "                                                                  'max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 6, 6, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 6, 6, 448)   1344        ['conv2d_174[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 6, 6, 448)    0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 6, 6, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 6, 6, 384)    1548288     ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 6, 6, 384)   1152        ['conv2d_171[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 6, 6, 384)   1152        ['conv2d_175[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_16 (AverageP  (None, 6, 6, 1280)  0           ['mixed8[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 6, 6, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 6, 6, 384)   1152        ['conv2d_172[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 6, 6, 384)   1152        ['conv2d_173[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 6, 6, 384)   1152        ['conv2d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 6, 6, 384)   1152        ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 6, 6, 192)    245760      ['average_pooling2d_16[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 6, 6, 320)   960         ['conv2d_170[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_176[0][0]']\n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 6, 6, 192)   576         ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 6, 6, 768)    0           ['activation_172[0][0]',         \n",
            "                                                                  'activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 6, 6, 768)    0           ['activation_176[0][0]',         \n",
            "                                                                  'activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 6, 6, 2048)   0           ['activation_170[0][0]',         \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate_2[0][0]',          \n",
            "                                                                  'activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 6, 6, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 6, 6, 448)   1344        ['conv2d_183[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 6, 6, 448)    0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 6, 6, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 6, 6, 384)    1548288     ['activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 6, 6, 384)   1152        ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 6, 6, 384)   1152        ['conv2d_184[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 6, 6, 384)    442368      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_17 (AverageP  (None, 6, 6, 2048)  0           ['mixed9[0][0]']                 \n",
            " ooling2D)                                                                                        \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 6, 6, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 6, 6, 384)   1152        ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 6, 6, 384)   1152        ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 6, 6, 384)   1152        ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 6, 6, 384)   1152        ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 6, 6, 192)    393216      ['average_pooling2d_17[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 6, 6, 320)   960         ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 6, 6, 384)    0           ['batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 6, 6, 192)   576         ['conv2d_187[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 6, 6, 320)    0           ['batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 6, 6, 768)    0           ['activation_181[0][0]',         \n",
            "                                                                  'activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 6, 6, 768)    0           ['activation_185[0][0]',         \n",
            "                                                                  'activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 6, 6, 192)    0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 6, 6, 2048)   0           ['activation_179[0][0]',         \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_3[0][0]',          \n",
            "                                                                  'activation_187[0][0]']         \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20490       ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,823,274\n",
            "Trainable params: 21,788,842\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 32s 96ms/step - loss: 0.5031 - accuracy: 0.8403\n",
            "Test Loss: 0.5030937790870667 Test Accuracy: 0.8403000235557556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.88      0.83      1000\n",
            "           1       0.99      0.85      0.91      1000\n",
            "           2       0.76      0.90      0.83      1000\n",
            "           3       0.75      0.73      0.74      1000\n",
            "           4       0.95      0.74      0.83      1000\n",
            "           5       0.81      0.83      0.82      1000\n",
            "           6       0.98      0.83      0.89      1000\n",
            "           7       0.71      0.95      0.82      1000\n",
            "           8       0.97      0.76      0.85      1000\n",
            "           9       0.86      0.95      0.90      1000\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.86      0.84      0.84     10000\n",
            "weighted avg       0.86      0.84      0.84     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "flHwzE3TOmsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S_F3T00iOmus"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}